{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from oml.datasets.retrieval import get_retrieval_datasets\n",
    "from oml.lightning.callbacks.metric import MetricValCallback\n",
    "from oml.lightning.modules.retrieval import RetrievalModule\n",
    "from pytorch_lightning.plugins import DDPPlugin\n",
    "from torch.utils.data import DataLoader\n",
    "from oml.utils.visualisation import RetrievalVisualizer\n",
    "from oml.metrics.embeddings import EmbeddingMetrics\n",
    "from oml.registry.models import get_extractor_by_cfg\n",
    "from oml.utils.images.images import tensor_to_numpy_image, imread_cv2\n",
    "from oml.utils.images.augs import get_default_transforms_albu\n",
    "\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.max_rows', 330)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "if \"TEST_RUN\" in os.environ:\n",
    "    dataset_root = Path(\"../tests/test_examples/data/\")\n",
    "    weights = \"random\"\n",
    "    gpus = 0\n",
    "    strategy = None\n",
    "    n_workers = 0\n",
    "else:\n",
    "    gpus = 1\n",
    "    strategy = DDPPlugin(find_unused_parameters=False)\n",
    "    n_workers = 10\n",
    "    \n",
    "    dataset_root = Path(\"/nydl/data/DeepFashion_InShop\")\n",
    "    weights = \"/nydl/logs/cur/ml/deepfashion/2022-05-27_13-54-34_deepfashion/checkpoints/best.ckpt\"\n",
    "\n",
    "#     dataset_root = Path(\"/nydl/data/whales\")\n",
    "#     weights = \"pretrained_dino\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = get_retrieval_datasets(dataset_root, im_size=512, \n",
    "                                                      pad_ratio_train=0, pad_ratio_val=0,\n",
    "                                                      train_transform=get_default_transforms_albu())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-satellite",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "from oml.lightning.entrypoints.train import main\n",
    "from oml.registry.transforms import AUGS_REGISTRY\n",
    "from oml.utils.images.augs import get_all_augs\n",
    "\n",
    "augs = get_all_augs()\n",
    "    \n",
    "for p in range(3):\n",
    "    n = 6\n",
    "    plt.figure(figsize=(40,40))\n",
    "    plt.subplot(1, n + 1, 1)\n",
    "    im = train_dataset.read_image(p+878)\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')\n",
    "    for i in range(1, n + 1):\n",
    "        plt.subplot(1, n + 1, i + 1)\n",
    "        plt.imshow(augs(image=im)['image'])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "df = train_dataset.df\n",
    "\n",
    "df[\"count\"] = 1\n",
    "y = df.groupby(\"label\").count()[\"count\"]\n",
    "\n",
    "covered, uncovered, auged = 0, 0, 0\n",
    "k = 8\n",
    "\n",
    "for sz, count in Counter(y).items():\n",
    "    if sz <= k:\n",
    "        covered += count\n",
    "        \n",
    "        auged += ((k - sz) / k) * count\n",
    "        \n",
    "    else:\n",
    "        uncovered += count\n",
    "        \n",
    "print(covered / (covered + uncovered))\n",
    "print(auged / (covered + uncovered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-trustee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(1):\n",
    "    plt.imshow(tensor_to_numpy_image(train_dataset[105][\"input_tensors\"]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-catch",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cfg = {\"name\": \"vit\",\n",
    "        \"args\": {\n",
    "          \"arch\": \"vits8\",\n",
    "          \"normalise_features\": False,\n",
    "          \"use_multi_scale\": True,\n",
    "          \"weights\": weights,\n",
    "          \"strict_load\": True\n",
    "        }}\n",
    "\n",
    "# cfg = {\"name\": \"resnet\",\n",
    "#         \"args\": {\n",
    "#           \"arch\": \"resnet50\",\n",
    "#           \"normalise_features\": True,\n",
    "#           \"remove_fc\": True,\n",
    "#           \"weights\": \"pretrained\",\n",
    "#           \"strict_load\": False,\n",
    "#           \"gem_p\": 7,\n",
    "#           \"hid_dim\": None,\n",
    "#            \"out_dim\": None\n",
    "#         }}\n",
    "\n",
    "val_loader = DataLoader(dataset=valid_dataset, batch_size=20, num_workers=20, drop_last=False)\n",
    "\n",
    "\n",
    "model = get_extractor_by_cfg(cfg)\n",
    "\n",
    "pl_model = RetrievalModule(model=model, criterion=None, optimizer=None)\n",
    "\n",
    "clb_metric = MetricValCallback(metric=EmbeddingMetrics(extra_keys=(\"paths\", \"x1\", \"x2\", \"y1\", \"y2\")))\n",
    "\n",
    "trainer = pl.Trainer(gpus=gpus,\n",
    "                     num_nodes=1,\n",
    "                     strategy=strategy,\n",
    "                     replace_sampler_ddp=False,\n",
    "                     callbacks=[clb_metric],\n",
    "                    )\n",
    "\n",
    "ret = trainer.validate(dataloaders=val_loader,\n",
    "                       verbose=True,\n",
    "                       model=pl_model\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc = RetrievalVisualizer.from_embeddings_metric(clb_metric.metric)\n",
    "n_query = clb_metric.metric.distance_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-vertex",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(min(150, n_query)):\n",
    "    calc.visualise(query_idx=500 + i, top_k=1, skip_no_errors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-double",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
